{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Import Necessary Libraries"
      ],
      "metadata": {
        "id": "WZHBCm3aWmlt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "O5pAhe64KD0S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB9na99jKD0V"
      },
      "source": [
        "## Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "40lYJgEsKD0X"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1pi8_kjKD0Y",
        "outputId": "65171757-cd48-415e-8235-21f7982c90ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 550176 entries, 0 to 550175\n",
            "Data columns (total 8 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   ProductType        550176 non-null  object \n",
            " 1   Manufacturer       550176 non-null  object \n",
            " 2   Area Code          550176 non-null  object \n",
            " 3   Sourcing Channel   550176 non-null  object \n",
            " 4   Product Size       550176 non-null  object \n",
            " 5   Product Type       550176 non-null  object \n",
            " 6   Month of Sourcing  550176 non-null  object \n",
            " 7   Sourcing Cost      550176 non-null  float64\n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 33.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA_xAbhtOfSp",
        "outputId": "5d6c6cb0-c792-4ecb-ce9a-20c6cba8eadf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "L2NyZdfqKD0Z",
        "outputId": "460e2eda-e771-4149-deb8-c824b9cfd7dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ProductType Manufacturer Area Code Sourcing Channel Product Size  \\\n",
              "0        NTM3           X1       A28        WHOLESALE        Large   \n",
              "\n",
              "  Product Type Month of Sourcing  Sourcing Cost  \n",
              "0       Powder            May-21          10.16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-034d2db9-f2af-4ef5-89cf-a779c09469df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductType</th>\n",
              "      <th>Manufacturer</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>Sourcing Channel</th>\n",
              "      <th>Product Size</th>\n",
              "      <th>Product Type</th>\n",
              "      <th>Month of Sourcing</th>\n",
              "      <th>Sourcing Cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NTM3</td>\n",
              "      <td>X1</td>\n",
              "      <td>A28</td>\n",
              "      <td>WHOLESALE</td>\n",
              "      <td>Large</td>\n",
              "      <td>Powder</td>\n",
              "      <td>May-21</td>\n",
              "      <td>10.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-034d2db9-f2af-4ef5-89cf-a779c09469df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-034d2db9-f2af-4ef5-89cf-a779c09469df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-034d2db9-f2af-4ef5-89cf-a779c09469df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Month of Sourcing'] = pd.to_datetime(df['Month of Sourcing'], format='%b-%y')\n"
      ],
      "metadata": {
        "id": "Q3X0HtpnO4Y6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X72CDLk1KD0Z"
      },
      "outputs": [],
      "source": [
        "df['Year of Sourcing'] = df['Month of Sourcing'].dt.year\n",
        "df['Day of Sourcing'] = df['Month of Sourcing'].dt.day\n",
        "df[\"Month of Sourcing\"] = df[\"Month of Sourcing\"].dt.month\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "lL8MWWsLKD0a",
        "outputId": "331e7912-5346-4a99-c02d-9b70bfa304b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ProductType Manufacturer Area Code Sourcing Channel Product Size  \\\n",
              "0        NTM3           X1       A28        WHOLESALE        Large   \n",
              "\n",
              "  Product Type  Month of Sourcing  Sourcing Cost  Year of Sourcing  \\\n",
              "0       Powder                  5          10.16              2021   \n",
              "\n",
              "   Day of Sourcing  \n",
              "0                1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98725dc7-ceca-4943-bf6c-35188ea728a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductType</th>\n",
              "      <th>Manufacturer</th>\n",
              "      <th>Area Code</th>\n",
              "      <th>Sourcing Channel</th>\n",
              "      <th>Product Size</th>\n",
              "      <th>Product Type</th>\n",
              "      <th>Month of Sourcing</th>\n",
              "      <th>Sourcing Cost</th>\n",
              "      <th>Year of Sourcing</th>\n",
              "      <th>Day of Sourcing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NTM3</td>\n",
              "      <td>X1</td>\n",
              "      <td>A28</td>\n",
              "      <td>WHOLESALE</td>\n",
              "      <td>Large</td>\n",
              "      <td>Powder</td>\n",
              "      <td>5</td>\n",
              "      <td>10.16</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98725dc7-ceca-4943-bf6c-35188ea728a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98725dc7-ceca-4943-bf6c-35188ea728a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98725dc7-ceca-4943-bf6c-35188ea728a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmiWwZAZKD0b"
      },
      "source": [
        "## Identifying Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfxcrGG8KD0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "054671cd-3ce3-4d8d-f642-748f98215b64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-63-6a48aee715d5>, line 14)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         and are passed to the built-in compile function.\"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSyntaxError\u001b[0m: invalid decimal literal (<ipython-input-63-6a48aee715d5>, line 14)"
          ]
        }
      ],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "def outliers_zscore(data):\n",
        "    #Identifying outliers using Z-scores\n",
        "    zs = zscore(data)\n",
        "    outliers = data[(zs > 3) | (zs < -3)]\n",
        "    return outliers\n",
        "\n",
        "def outliers_iqr(data):\n",
        "    #Identifying outliers using Interquartile Range\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5  IQR\n",
        "    upper_bound = Q3 + 1.5  IQR\n",
        "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
        "    return outliers\n",
        "\n",
        "def outliers_boxplot(column, data):\n",
        "    #Visualizing outliers using a boxplot for a specific column in a DataFrame\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.boxplot(data[column], vert=False)\n",
        "    plt.title(f'Boxplot of {column}')\n",
        "    plt.xlabel('Values')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waS9oW7PKD0c"
      },
      "outputs": [],
      "source": [
        "for column in df.columns:\n",
        "    if df[column].dtype in ['int64', 'float64']:  # Modify as needed for different data types\n",
        "        num_outliers_zscore = len(outliers_zscore(df[column]))\n",
        "        num_outliers_iqr = len(outliers_iqr(df[column]))\n",
        "        print(f\"Column: {column}\")\n",
        "        print(f\"  Number of outliers by Z-score: {num_outliers_zscore}\")\n",
        "        print(f\"  Number of outliers by IQR: {num_outliers_iqr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGxOOnCpKD0d"
      },
      "outputs": [],
      "source": [
        "for column in df.columns:\n",
        "    if df[column].dtype in ['int64', 'float64']:\n",
        "        outliers_boxplot(column, df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmmvycCTKD0f"
      },
      "outputs": [],
      "source": [
        "df['Sourcing Cost'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge0SKyiNKD0g"
      },
      "outputs": [],
      "source": [
        "df_with_outliers = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-7u6piLKD0g"
      },
      "source": [
        "## Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of6jdxmqKD0g"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_trimming(df, column):\n",
        "    # Will remove all outliers regardless\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5  IQR\n",
        "    upper_bound = Q3 + 1.5  IQR\n",
        "\n",
        "    # Condition for non-outliers\n",
        "    condition = (df[column] >= lower_bound) & (df[column] <= upper_bound)\n",
        "    return df[condition]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yldfPhD_KD0g"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_capping(df, column):\n",
        "    # Will set them to nearest values within acceptable rage of IQR\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5  IQR\n",
        "    upper_bound = Q3 + 1.5  IQR\n",
        "\n",
        "    df[column] = df[column].apply(lambda x: upper_bound if x > upper_bound else (lower_bound if x < lower_bound else x))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4TPr_VtKD0g"
      },
      "outputs": [],
      "source": [
        "df_capped = remove_outliers_capping(df, 'Sourcing Cost')\n",
        "df_capped.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOpNWR0BKD0h"
      },
      "outputs": [],
      "source": [
        "def bin_data(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5  IQR\n",
        "    upper_bound = Q3 + 1.5  IQR\n",
        "\n",
        "    bins = [df[column].min(), lower_bound, Q1, Q3, upper_bound, df[column].max()]\n",
        "    labels = ['Extreme Low', 'Low', 'Moderate', 'High', 'Extreme High']\n",
        "    df['binned'] = pd.cut(df[column], bins=bins, labels=labels, include_lowest=True)\n",
        "    return df\n",
        "\n",
        "def remove_extreme_bins(df, column_bin):\n",
        "    # Filter out rows where the bin label is 'Extreme High' or 'Extreme Low'\n",
        "    condition = ~df[column_bin].isin(['Extreme High', 'Extreme Low'])\n",
        "    return df[condition]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8WCei1_KD0h"
      },
      "outputs": [],
      "source": [
        "df = df_capped.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Used Capping Instead of Binning as it is more suitable for given finincial data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bebeXGl0PXax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuGXBfl4KD0i"
      },
      "outputs": [],
      "source": [
        "columns_with_null = df.columns[df.isnull().any()].tolist()\n",
        "columns_with_null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEh2sq00KD0i"
      },
      "source": [
        "## Feature Selection and EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgBRI0b4KD0i"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dnuRExvKD0i"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_mappings = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "# Now label_mappings contains the mappings of original categorical values to encoded numerical values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAqm_7G7KD0i"
      },
      "outputs": [],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-lWjWvWKD0j"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_correlation_matrix(df):\n",
        "    corr_matrix = df.corr()\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.show()\n",
        "plot_correlation_matrix(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF4KTs2aKD0j"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "def select_features_kbest(X, y, k):\n",
        "    # Select top k features based on the F-score\n",
        "    selector = SelectKBest(score_func=f_classif, k=k)\n",
        "    selector.fit(X, y)\n",
        "    scores = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Score': selector.scores_\n",
        "    }).sort_values(by='Score', ascending=False)\n",
        "    return scores\n",
        "\n",
        "X = df.drop('Sourcing Cost', axis=1)\n",
        "y = df['Sourcing Cost']\n",
        "top_features = select_features_kbest(X, y, k=5)\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuBwMc9qKD0j"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=top_features, x='Score', y='Feature', orient='h')\n",
        "plt.title('Feature Importance Scores')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We infer that, to determin Sourcing Cost\n",
        "1. Manufacturer is the strongest feature followed by Sourcing Channel\n",
        "2. Year and month of sourcing ans 'ProductType' are also strong\n",
        "3. Area code, Product size, 'Product Type' are realtively weak\n",
        "4. Day of sourcing is the weakest"
      ],
      "metadata": {
        "id": "F4UoUYVjPrda"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xjTCBmDKD0k"
      },
      "source": [
        "###Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58QleqI7KD0l"
      },
      "outputs": [],
      "source": [
        "df_capped.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqqEUNsLKD0m"
      },
      "outputs": [],
      "source": [
        "# Function to plot a histogram for a numerical column\n",
        "def plot_histogram(data, column, bins=30):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data[column], bins=bins, kde=True)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "# To plot a count plot for a categorical column\n",
        "def plot_count(data, column):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.countplot(data=data, y=column, order = data[column].value_counts().index)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.xlabel('Count')\n",
        "    plt.ylabel(column)\n",
        "    plt.show()\n",
        "# Function to plot a time series plot for a dataset with time and value columns\n",
        "def plot_time_series(data, time_column, value_column):\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sns.lineplot(data=data, x=time_column, y=value_column, marker='o')\n",
        "    plt.title(f'Time Series Plot of {value_column} Over {time_column}')\n",
        "    plt.xlabel(time_column)\n",
        "    plt.ylabel(value_column)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjPPyaX9KD0m"
      },
      "outputs": [],
      "source": [
        "plot_histogram(df_capped, 'Sourcing Cost')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAIHvcyTKD0n"
      },
      "outputs": [],
      "source": [
        "# Plot count of each category in different columns\n",
        "plot_count(df_capped, 'ProductType')\n",
        "plot_count(df_capped, 'Manufacturer')\n",
        "plot_count(df_capped, 'Area Code')\n",
        "plot_count(df_capped, 'Sourcing Channel')\n",
        "plot_count(df_capped, 'Product Size')\n",
        "plot_count(df_capped, 'Product Type')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mpT1PHiKD0n"
      },
      "outputs": [],
      "source": [
        "#Plot time series graph\n",
        "plot_time_series(df_capped, 'Month of Sourcing', 'Sourcing Cost')\n",
        "plot_time_series(df_capped, 'Year of Sourcing', 'Sourcing Cost')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(5)"
      ],
      "metadata": {
        "id": "fKsBRlpSQs-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Plots line plot for Sourcing cost\n",
        "from matplotlib import pyplot as plt\n",
        "df_test['Sourcing Cost'].plot(kind='line', figsize=(8, 4), title='Sourcing Cost')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "7Uk4XIPnSiwQ"
      }
    },
    {
      "source": [
        "#group the data by 'ProductType', calculate the size of each group, and plots the result as a horizontal bar plot\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df_test.groupby('ProductType').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "syFj5LzoSYvK"
      }
    },
    {
      "source": [
        "#Histogram for Sourcing Cost\n",
        "from matplotlib import pyplot as plt\n",
        "df_test['Sourcing Cost'].plot(kind='hist', bins=20, title='Sourcing Cost')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "dHZYksTESTX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling\n"
      ],
      "metadata": {
        "id": "Q8dVT8yxOrYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Regressor along with Label encoding technique"
      ],
      "metadata": {
        "id": "f6HW7rPETotR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Test.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "encoder = LabelEncoder()\n",
        "train_data['Month of Sourcing'] = pd.to_datetime(train_data['Month of Sourcing'], format='%b-%y')\n",
        "train_data['Month'] = train_data['Month of Sourcing'].dt.month\n",
        "train_data['Year'] = train_data['Month of Sourcing'].dt.year\n",
        "train_data['ProductType'] = encoder.fit_transform(train_data['ProductType'])\n",
        "train_data['Manufacturer'] = encoder.fit_transform(train_data['Manufacturer'])\n",
        "train_data['Area Code'] = encoder.fit_transform(train_data['Area Code'])\n",
        "train_data['Sourcing Channel'] = encoder.fit_transform(train_data['Sourcing Channel'])\n",
        "train_data['Product Size'] = encoder.fit_transform(train_data['Product Size'])\n",
        "train_data['Product Type'] = encoder.fit_transform(train_data['Product Type'])\n",
        "\n",
        "test_data['Month of Sourcing'] = pd.to_datetime(test_data['Month of Sourcing'], format='%b-%y')\n",
        "test_data['Month'] = test_data['Month of Sourcing'].dt.month\n",
        "test_data['Year'] = test_data['Month of Sourcing'].dt.year\n",
        "test_data['ProductType'] = encoder.fit_transform(test_data['ProductType'])\n",
        "test_data['Manufacturer'] = encoder.fit_transform(test_data['Manufacturer'])\n",
        "test_data['Area Code'] = encoder.fit_transform(test_data['Area Code'])\n",
        "test_data['Sourcing Channel'] = encoder.fit_transform(test_data['Sourcing Channel'])\n",
        "test_data['Product Size'] = encoder.fit_transform(test_data['Product Size'])\n",
        "test_data['Product Type'] = encoder.fit_transform(test_data['Product Type'])\n",
        "\n",
        "# Defining features and target variable\n",
        "features = ['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type', 'Month', 'Year']\n",
        "target = 'Sourcing Cost'\n",
        "\n",
        "# Split the data\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "\n",
        "# Random Forest Regressor model\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "X_test = test_data[features]\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "test_data['Predicted Sourcing Cost'] = y_pred\n",
        "\n",
        "print(test_data)\n"
      ],
      "metadata": {
        "id": "R3pymEiISLuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Applied K fold cross validation technique but was not efficcient"
      ],
      "metadata": {
        "id": "ni23PJKER0uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Test.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "def preprocess_data(data):\n",
        "    data['Month of Sourcing'] = pd.to_datetime(data['Month of Sourcing'], format='%b-%y')\n",
        "    data['Month'] = data['Month of Sourcing'].dt.month\n",
        "    data['Year'] = data['Month of Sourcing'].dt.year\n",
        "    data['ProductType'] = encoder.fit_transform(data['ProductType'])\n",
        "    data['Manufacturer'] = encoder.fit_transform(data['Manufacturer'])\n",
        "    data['Area Code'] = encoder.fit_transform(data['Area Code'])\n",
        "    data['Sourcing Channel'] = encoder.fit_transform(data['Sourcing Channel'])\n",
        "    data['Product Size'] = encoder.fit_transform(data['Product Size'])\n",
        "    data['Product Type'] = encoder.fit_transform(data['Product Type'])\n",
        "    return data\n",
        "\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data)\n",
        "\n",
        "# Defining features and target variable\n",
        "features = ['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type', 'Month', 'Year']\n",
        "target = 'Sourcing Cost'\n",
        "\n",
        "# Split the data\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "\n",
        "# Random Forest Regressor model\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# K-fold Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model_rf, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on test data\n",
        "X_test = test_data[features]\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "test_data['Predicted Sourcing Cost'] = y_pred\n",
        "\n",
        "print(\"Cross-validation MSE scores:\", -cv_scores)\n",
        "print(\"Mean CV MSE:\", -cv_scores.mean())\n",
        "print(test_data)\n"
      ],
      "metadata": {
        "id": "g-nQ0Yn8RDT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print acatual vs Predicted for Random Forest Regressor\n",
        "# Extract actual values from the test dataset\n",
        "y_actual = test_data['Sourcing Cost']\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_actual, y_pred)\n",
        "mae = mean_absolute_error(y_actual, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_actual, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")\n",
        "\n",
        "comparison_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_pred})\n",
        "print(comparison_df.head())\n"
      ],
      "metadata": {
        "id": "rJntbybKUKBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " GradientBoostingRegressor, ExtraTreesRegressor"
      ],
      "metadata": {
        "id": "_2Ts10950XgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
        "\n",
        "# Initialization\n",
        "models = {\n",
        "    'Gradient Boosting Regressor': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'Extra Trees Regressor': ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_actual, y_pred)\n",
        "    mae = mean_absolute_error(y_actual, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_actual, y_pred)\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "    print(f\"R-squared (R2) Score: {r2}\")\n",
        "    print()\n",
        "\n",
        "    # Saving the model to compare later\n",
        "    test_data[f'Predicted Sourcing Cost - {name}'] = y_pred\n"
      ],
      "metadata": {
        "id": "OUtIEungVQsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "ag-RjAQ20U9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jYEGTn9w0U3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialize SVR model\n",
        "model_svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "\n",
        "# Train SVR model\n",
        "model_svr.fit(X_train, y_train)\n",
        "\n",
        "# Predict using SVR model\n",
        "y_pred_svr = model_svr.predict(X_test)\n",
        "\n",
        "# Evaluate SVR model\n",
        "mse_svr = mean_squared_error(y_actual, y_pred_svr)\n",
        "mae_svr = mean_absolute_error(y_actual, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "r2_svr = r2_score(y_actual, y_pred_svr)\n",
        "\n",
        "print(\"Support Vector Regressor (SVR) Model Evaluation:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_svr}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_svr}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_svr}\")\n",
        "print(f\"R-squared (R2) Score: {r2_svr}\")\n",
        "\n",
        "# Save predicted values for comparison\n",
        "test_data['Predicted Sourcing Cost - SVR'] = y_pred_svr\n"
      ],
      "metadata": {
        "id": "nAd2UTLD0RHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "id": "YVCMljwCS2Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Other Regression models"
      ],
      "metadata": {
        "id": "UTKH9YHMUcrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Initialization\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'ElasticNet Regression': ElasticNet(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
        "    'XGBoost Regressor': XGBRegressor(),\n",
        "    'LightGBM Regressor': LGBMRegressor(),\n",
        "    'CatBoost Regressor': CatBoostRegressor(verbose=0)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_actual, y_pred)\n",
        "    mae = mean_absolute_error(y_actual, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_actual, y_pred)\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "    print(f\"R-squared (R2) Score: {r2}\")\n",
        "\n",
        "    # Prints actual vs. predicted values\n",
        "    print(\"Actual vs. Predicted:\")\n",
        "    comparison_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_pred})\n",
        "    print(comparison_df.head())\n",
        "\n",
        "    print('\\n' + '-'50 + '\\n')\n"
      ],
      "metadata": {
        "id": "Rf4M8XvOVtNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost stands out for its effectiveness due to several key features:\n",
        "\n",
        "Gradient Boosting Technique: Sequential model building corrects errors, reducing bias and variance for better generalization.\n",
        "\n",
        "Regularization: L1/L2 regularization prevents overfitting, promoting simpler, more generalizable models.\n",
        "\n",
        "Tree Pruning: Eliminates non-contributing splits, fostering simpler, interpretable trees.\n",
        "\n",
        "Handling Missing Values: Built-in handling reduces reliance on imputation, preserving data integrity.\n",
        "\n",
        "Feature Importance: Provides insights for informed feature selection and engineering, enhancing model accuracy.\n",
        "\n",
        "Parallel Processing: Efficiently scales for large datasets, leveraging CPU cores for faster training.\n",
        "\n",
        "Optimized Implementation: C++ implementation ensures speed and memory efficiency, reducing training times.\n",
        "\n",
        "Tuning Flexibility: Wide hyperparameter range allows tailored optimization for diverse datasets.\n",
        "\n",
        "Ensemble Approach: Combines weak learners for robust, accurate predictions.\n",
        "\n",
        "Competitive Success: Proven track record in ML competitions underscores its versatility and effectiveness."
      ],
      "metadata": {
        "id": "kySRzCiyy4Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Models"
      ],
      "metadata": {
        "id": "Ldr3nQr6ysfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM"
      ],
      "metadata": {
        "id": "8mTXQniSqU9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Initialize LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "lstm_model.add(LSTM(units=50))\n",
        "lstm_model.add(Dense(units=1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
        "\n",
        "# Evaluate LSTM model on the test set\n",
        "y_pred_lstm = lstm_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse_lstm = mean_squared_error(y_actual, y_pred_lstm)\n",
        "mae_lstm = mean_absolute_error(y_actual, y_pred_lstm)\n",
        "rmse_lstm = np.sqrt(mse_lstm)\n",
        "r2_lstm = r2_score(y_actual, y_pred_lstm)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"LSTM Model Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_lstm}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_lstm}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_lstm}\")\n",
        "print(f\"R-squared (R2) Score: {r2_lstm}\\n\")\n",
        "test_data['Predicted Sourcing Cost - LSTM'] = y_pred_lstm\n"
      ],
      "metadata": {
        "id": "8GtqA8a-qTAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sequential Model"
      ],
      "metadata": {
        "id": "H4NWBRVwh_nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Test.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def preprocess_data(data):\n",
        "    data['Month of Sourcing'] = pd.to_datetime(data['Month of Sourcing'], format='%b-%y')\n",
        "    data['Month'] = data['Month of Sourcing'].dt.month\n",
        "    data['Year'] = data['Month of Sourcing'].dt.year\n",
        "    data['ProductType'] = encoder.fit_transform(data['ProductType'])\n",
        "    data['Manufacturer'] = encoder.fit_transform(data['Manufacturer'])\n",
        "    data['Area Code'] = encoder.fit_transform(data['Area Code'])\n",
        "    data['Sourcing Channel'] = encoder.fit_transform(data['Sourcing Channel'])\n",
        "    data['Product Size'] = encoder.fit_transform(data['Product Size'])\n",
        "    data['Product Type'] = encoder.fit_transform(data['Product Type'])\n",
        "    data['Sourcing Cost'] = scaler.fit_transform(data[['Sourcing Cost']])\n",
        "    return data\n",
        "\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data)\n",
        "\n",
        "# Defining features and target variable\n",
        "features = ['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type', 'Month', 'Year']\n",
        "target = 'Sourcing Cost'\n",
        "\n",
        "# Split the data\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(features)]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, batch_size=32, verbose=1)\n",
        "\n",
        "# Predictions on test data\n",
        "X_test = test_data[features]\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled).flatten()  # Inverse transform to get actual values\n",
        "\n",
        "# Get the actual values for the test data\n",
        "y_actual = scaler.inverse_transform(test_data[[target]]).flatten()\n",
        "\n",
        "# Print actual vs predicted\n",
        "print(\"Actual vs Predicted:\")\n",
        "comparison_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_pred})\n",
        "print(comparison_df.head())\n"
      ],
      "metadata": {
        "id": "7ja_uUChg7HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import  StandardScaler\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Test.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "encoder = LabelEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def preprocess_data(data):\n",
        "    data['Month of Sourcing'] = pd.to_datetime(data['Month of Sourcing'], format='%b-%y')\n",
        "    data['Month'] = data['Month of Sourcing'].dt.month\n",
        "    data['Year'] = data['Month of Sourcing'].dt.year\n",
        "    data['ProductType'] = encoder.fit_transform(data['ProductType'])\n",
        "    data['Manufacturer'] = encoder.fit_transform(data['Manufacturer'])\n",
        "    data['Area Code'] = encoder.fit_transform(data['Area Code'])\n",
        "    data['Sourcing Channel'] = encoder.fit_transform(data['Sourcing Channel'])\n",
        "    data['Product Size'] = encoder.fit_transform(data['Product Size'])\n",
        "    data['Product Type'] = encoder.fit_transform(data['Product Type'])\n",
        "    data['Sourcing Cost'] = scaler.fit_transform(data[['Sourcing Cost']])\n",
        "    return data\n",
        "\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data)\n",
        "\n",
        "# Defining features and target variable\n",
        "features = ['ProductType', 'Manufacturer', 'Area Code', 'Sourcing Channel', 'Product Size', 'Product Type', 'Month', 'Year']\n",
        "target = 'Sourcing Cost'\n",
        "\n",
        "# Split the data\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(features)]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, batch_size=32, verbose=1)\n",
        "\n",
        "# Predictions on test data\n",
        "X_test = test_data[features]\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "y_pred = scaler.inverse_transform(y_pred_scaled).flatten()  # Inverse transform to get actual values\n",
        "\n",
        "# Get the actual values for the test data\n",
        "y_actual = scaler.inverse_transform(test_data[[target]]).flatten()\n",
        "\n",
        "# Print actual vs predicted\n",
        "print(\"Actual vs Predicted:\")\n",
        "comparison_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_pred})\n",
        "print(comparison_df.head())\n",
        "\n",
        "# Multilayer Perceptron (MLP) Model\n",
        "mlp_model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=[len(features)]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "mlp_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "mlp_history = mlp_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=4, batch_size=32, verbose=1)\n",
        "mlp_y_pred_scaled = mlp_model.predict(X_test)\n",
        "mlp_y_pred = scaler.inverse_transform(mlp_y_pred_scaled).flatten()\n",
        "print(\"Actual vs Predicted (MLP):\")\n",
        "mlp_comparison_df = pd.DataFrame({'Actual': y_actual, 'Predicted': mlp_y_pred})\n",
        "print(mlp_comparison_df.head())\n"
      ],
      "metadata": {
        "id": "OY4PlyMglqQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Deep learning models underperform due to requirements of large datasets for effective generalization and complexities in hyperparameter tuning, feature engineering, and managing overfitting, leading to longer training times and computational demands.\n",
        "\n",
        "2. Lack of interpretability and challenges in handling limited data diversity further hinder deep learning model performance, necessitating careful consideration of suitability for specific tasks and availability of resources for training and optimization."
      ],
      "metadata": {
        "id": "QpHoH1gVzw9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Based on the evaluation metrics and comparison of different regression models including Random Forest, Gradient Boosting, Extra Trees, and Support Vector Regression (SVR), it can be concluded that XGBoost (Extreme Gradient Boosting) performs the best for the given task of predicting sourcing costs. This conclusion is drawn from several factors:\n",
        "\n",
        "1. Performance Metrics: XGBoost consistently shows lower Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) compared to other models, indicating better accuracy in predicting sourcing costs.\n",
        "\n",
        "2. R-squared (R2) Score: XGBoost also demonstrates higher R-squared (R2) scores, suggesting better overall goodness of fit and explaining more variance in the data compared to alternative models.\n",
        "\n",
        "3. Robustness: XGBoost's robustness is evidenced by its performance across multiple evaluation metrics and its ability to handle complex relationships and non-linear patterns in the data.\n",
        "\n",
        "4. Consistency: XGBoost consistently outperforms other models across different datasets and scenarios, making it a reliable choice for predictive modeling tasks.\n",
        "\n",
        "5. Ensemble Learning: XGBoost's ensemble approach, combining predictions from multiple weak learners (decision trees), helps in reducing bias and variance, leading to more accurate and stable predictions.\n",
        "\n",
        "In conclusion, based on the evaluation results and considerations of accuracy, robustness, and consistency, XGBoost emerges as the best model for predicting sourcing costs."
      ],
      "metadata": {
        "id": "rD1taxY30nRY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThS_22z8YjEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}